{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing  : First Project \n",
    "## TripAdvisor Recommendation Challenge \n",
    "Beating BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../offerings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data_hotels \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../offerings.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m data_reviews \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../offerings.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_hotels = pd.read_csv('../offerings.csv')\n",
    "data_reviews = pd.read_csv('../reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reviews = data_reviews.drop(columns=[\"id\", \"via_mobile\",\"author\",\"date\", \"date_stayed\",\"num_helpful_votes\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def fix_json_format(address_string):\n",
    "    address_string = re.sub(r\"'\", r'\"', address_string)\n",
    "    \n",
    "    return address_string\n",
    "#  Function to fix and convert address strings in the DataFrame\n",
    "def convert_review_string(address_string):\n",
    "    if isinstance(address_string, str):\n",
    "        fixed_string = fix_json_format(address_string)\n",
    "        return json.loads(fixed_string)  # Convert to dictionary\n",
    "    return address_string  # Return as is if not a string\n",
    "\n",
    "# Apply the function to the 'address' column\n",
    "data_reviews['ratings'] = data_reviews['ratings'].apply(convert_review_string)\n",
    "\n",
    "\n",
    "# Convert the 'address' column into a dataframe where each key becomes a new column\n",
    "reviews_df = pd.json_normalize(data_reviews['ratings'])\n",
    "\n",
    "# Now, concatenate this new dataframe to your original dataframe\n",
    "data_reviews = pd.concat([data_reviews, reviews_df], axis=1)\n",
    "\n",
    "# Optionally, you can drop the original 'address' column if you no longer need it\n",
    "data_reviews.drop(columns=['ratings','check_in_front_desk', 'business_service_(e_g_internet_access)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hotels = data_hotels.drop(columns=[\"phone\", \"details\",\"region_id\",\"type\", \"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Function to fix the JSON format, while preserving apostrophes in words\n",
    "def fix_json_format(address_string):\n",
    "\n",
    "\n",
    "    # 3. Detect all apostrophes inside double quotes and remove them\n",
    "    # This will remove any single quote (apostrophe) between a pair of double quotes\n",
    "    address_string = re.sub(r'(\"(?:[^\"\\\\]|\\\\.)*?)\\'(.*?\")', r'\\1\\2', address_string)\n",
    "\n",
    "    \n",
    "    # 4. Handle any double quotes inside a street address properly (if needed)\n",
    "    # Escape problematic double quotes inside actual string values like street names\n",
    "    address_string = re.sub(r'(?<!\\\\)\"([A-Za-z ]*)\"(?=\\s+Street)', r'\\\"\\1\\\"', address_string)\n",
    "    address_string = re.sub(r\"'\", r'\"', address_string)\n",
    "    \n",
    "    return address_string\n",
    "\n",
    "# Function to fix and convert address strings in the DataFrame\n",
    "def convert_address_string(address_string):\n",
    "    if isinstance(address_string, str):\n",
    "        fixed_string = fix_json_format(address_string)\n",
    "        return json.loads(fixed_string)  # Convert to dictionary\n",
    "    return address_string  # Return as is if not a string\n",
    "\n",
    "# Apply the function to the 'address' column\n",
    "data_hotels['address'] = data_hotels['address'].apply(convert_address_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'address' column into a dataframe where each key becomes a new column\n",
    "address_df = pd.json_normalize(data_hotels['address'])\n",
    "\n",
    "# Now, concatenate this new dataframe to your original dataframe\n",
    "data_hotels = pd.concat([data_hotels, address_df], axis=1)\n",
    "\n",
    "# Optionally, you can drop the original 'address' column if you no longer need it\n",
    "data_hotels.drop(columns=['address'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Calculate the average rating based on the specified columns\n",
    "data_reviews[\"rating\"] = data_reviews[[\n",
    "    \"service\", \"cleanliness\", \"overall\", \"value\", \n",
    "    \"location\", \"sleep_quality\", \"rooms\"\n",
    "]].mean(axis=1)\n",
    "\n",
    "data_reviews.drop(columns=[\"service\", \"cleanliness\", \"overall\", \"value\", \n",
    "    \"location\", \"sleep_quality\", \"rooms\"] , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns from 'hotel' table with 'hotel_' prefix\n",
    "hotel_columns = {col: f'hotel_{col}' for col in data_hotels.columns if col != 'offering_id'}\n",
    "\n",
    "# Rename columns from 'reviews' table with 'reviews_' prefix\n",
    "reviews_columns = {col: f'reviews_{col}' for col in data_reviews.columns if col != 'id'}\n",
    "\n",
    "data = pd.merge(data_reviews, data_hotels, left_on=\"offering_id\", right_on=\"id\", how=\"left\",suffixes=(\"_rewiew\", \"_hotel\"))\n",
    "data = data.drop(columns=[\"offering_id\"])\n",
    "\n",
    "data = data.rename(columns={**hotel_columns, **reviews_columns})\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>reviews_rating</th>\n",
       "      <th>hotel_hotel_class</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>hotel_region</th>\n",
       "      <th>hotel_street-address</th>\n",
       "      <th>hotel_postal-code</th>\n",
       "      <th>hotel_locality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stayed in a king suite for 11 nights and yes i...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93338</td>\n",
       "      <td>Hotel Beacon</td>\n",
       "      <td>NY</td>\n",
       "      <td>2130 Broadway at 75th Street</td>\n",
       "      <td>10023</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On every visit to NYC, the Hotel Beacon is the...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>93338</td>\n",
       "      <td>Hotel Beacon</td>\n",
       "      <td>NY</td>\n",
       "      <td>2130 Broadway at 75th Street</td>\n",
       "      <td>10023</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a great property in Midtown. We two di...</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1762573</td>\n",
       "      <td>Andaz 5th Avenue</td>\n",
       "      <td>NY</td>\n",
       "      <td>485 5th Avenue</td>\n",
       "      <td>10017</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Andaz is a nice hotel in a central locatio...</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1762573</td>\n",
       "      <td>Andaz 5th Avenue</td>\n",
       "      <td>NY</td>\n",
       "      <td>485 5th Avenue</td>\n",
       "      <td>10017</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have stayed at each of the US Andaz properti...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1762573</td>\n",
       "      <td>Andaz 5th Avenue</td>\n",
       "      <td>NY</td>\n",
       "      <td>485 5th Avenue</td>\n",
       "      <td>10017</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews_text  reviews_rating  \\\n",
       "0  Stayed in a king suite for 11 nights and yes i...        5.000000   \n",
       "1  On every visit to NYC, the Hotel Beacon is the...        5.000000   \n",
       "2  This is a great property in Midtown. We two di...        4.285714   \n",
       "3  The Andaz is a nice hotel in a central locatio...        4.857143   \n",
       "4  I have stayed at each of the US Andaz properti...        4.428571   \n",
       "\n",
       "   hotel_hotel_class  hotel_id        hotel_name hotel_region  \\\n",
       "0                3.0     93338      Hotel Beacon           NY   \n",
       "1                3.0     93338      Hotel Beacon           NY   \n",
       "2                4.0   1762573  Andaz 5th Avenue           NY   \n",
       "3                4.0   1762573  Andaz 5th Avenue           NY   \n",
       "4                4.0   1762573  Andaz 5th Avenue           NY   \n",
       "\n",
       "           hotel_street-address hotel_postal-code hotel_locality  \n",
       "0  2130 Broadway at 75th Street             10023  New York City  \n",
       "1  2130 Broadway at 75th Street             10023  New York City  \n",
       "2                485 5th Avenue             10017  New York City  \n",
       "3                485 5th Avenue             10017  New York City  \n",
       "4                485 5th Avenue             10017  New York City  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 841943 entries, 0 to 878560\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   reviews_text          841943 non-null  object \n",
      " 1   reviews_rating        841943 non-null  float64\n",
      " 2   hotel_hotel_class     841943 non-null  float64\n",
      " 3   hotel_id              841943 non-null  int64  \n",
      " 4   hotel_name            841943 non-null  object \n",
      " 5   hotel_region          841943 non-null  object \n",
      " 6   hotel_street-address  841943 non-null  object \n",
      " 7   hotel_postal-code     841943 non-null  object \n",
      " 8   hotel_locality        841943 non-null  object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 64.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM vs. My model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 56\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mse\n\u001b[1;32m     50\u001b[0m query \u001b[38;5;241m=\u001b[39m Query(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest breakfast\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     51\u001b[0m               avg_rating \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \n\u001b[1;32m     52\u001b[0m               region\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     53\u001b[0m               locality \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoston\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m similates_id \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mbm25_model(\u001b[43mdata\u001b[49m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected hotel:\u001b[39m\u001b[38;5;124m\"\u001b[39m , np\u001b[38;5;241m.\u001b[39munique(data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m similates_id][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhotel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhotel_region\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhotel_locality\u001b[39m\u001b[38;5;124m\"\u001b[39m]]))\n\u001b[1;32m     58\u001b[0m mse \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mevaluate(similates_id,data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "class Query:\n",
    "    def __init__(self, text, avg_rating, region\t, locality):\n",
    "        self.text = text\n",
    "        self.rating = avg_rating\n",
    "        self.region = region\n",
    "        self.locality = locality\n",
    "\n",
    "    def bm25_model(self, reviews):\n",
    "        filtered_reviews = reviews[(reviews['hotel_region'] == self.region) & (reviews['hotel_locality'] == self.locality)]\n",
    "        \n",
    "        corpus = filtered_reviews[\"reviews_text\"]\n",
    "        tokenized_corpus = [rating.split(\" \") for rating in corpus]\n",
    "\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        tokenized_query = self.text.split(\" \")\n",
    "        doc_scores = bm25.get_scores(tokenized_query)\n",
    "        most_related_place_bm = filtered_reviews.iloc[doc_scores.argmax()][\"hotel_id\"]\n",
    "        return most_related_place_bm\n",
    "\n",
    "    def my_model(self, reviews):\n",
    "        filtered_reviews = reviews[(reviews['hotel_region'] == self.region) & (reviews['hotel_locality'] == self.locality)]\n",
    "        \n",
    "        print(len(self.text.split(\" \")))\n",
    "        corpus = filtered_reviews[\"reviews_text\"][0:5]\n",
    "        tokenized_corpus = [rating.split(\" \") for rating in corpus]\n",
    "        print(tokenized_corpus)\n",
    "        corpus = filtered_reviews[\"reviews_text\"]\n",
    "        tokenized_corpus = [rating.split(\" \") for rating in corpus]\n",
    "\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        tokenized_query = self.text.split(\" \")\n",
    "        doc_scores = bm25.get_scores(tokenized_query)\n",
    "        most_related_place_bm = filtered_reviews.iloc[doc_scores.argmax()][\"hotel_id\"]\n",
    "        print(filtered_reviews.iloc[doc_scores.argmax()][\"reviews_text\"])\n",
    "        return most_related_place_bm\n",
    "\n",
    "    def evaluate(self, selected_place, reviews):\n",
    "        filtered_reviews = reviews[reviews['hotel_id'] == selected_place]\n",
    "        mse = 0 \n",
    "        for i in range(len(filtered_reviews)):\n",
    "            review = filtered_reviews.iloc[i]\n",
    "            mse += (self.rating - review[\"reviews_rating\"]) **2\n",
    "        mse /= filtered_reviews.shape[0]\n",
    "        return mse\n",
    "\n",
    "\n",
    "query = Query(text=\"best breakfast\", \n",
    "              avg_rating = 4, \n",
    "              region=\"MA\", \n",
    "              locality = \"Boston\")\n",
    "\n",
    "\n",
    "similates_id = query.bm25_model(data)\n",
    "print(\"Selected hotel:\" , np.unique(data[data['hotel_id'] == similates_id][[\"hotel_name\", \"hotel_region\", \"hotel_locality\"]]))\n",
    "mse = query.evaluate(similates_id,data)\n",
    "print(\"Mean Squared Error - BM25:\", mse)\n",
    "\n",
    "similates_id = query.my_model(data)\n",
    "print(\"Selected hotel:\" , np.unique(data[data['hotel_id'] == similates_id][[\"hotel_name\", \"hotel_region\", \"hotel_locality\"]]))\n",
    "mse = query.evaluate(similates_id,data)\n",
    "print(\"Mean Squared Error - My model:\", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
